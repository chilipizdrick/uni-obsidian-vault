```julia
function maxsum(a::AbstracArray)
	M = a[begin]
	M' = M
	i = firstindex(a)
	
	while i < lastindex(a)
		i += 1
		M', M = max(M'+a[i], a[i]), max(M, M')
	end
	return M
end
```

Итератор - это объект, который состоит из нескольких элементов или порождает некоторую посл. элементов


Генератор - вычисляет последовательность, она не хранится в памяти
(ну типа списочных выражений) вычисляется при итерировании, относится к ленивым вычислениям


чтобы объект был итерируемыый должны быть определены два метода iterate: с одним и двумя аргументами

```julia
iter = iterate(array, state)
pointedObject, nextState = iterate
```
когда выходит за границы - становится инстанцией nothing


Имплементируем итерирование при помощи итератора

```julia
function maxsum(array::AbstracArray)
	iter = iterate(array)
	M',state = iter  # \prime[tab]
	M = M'
	iter = iterate(array, state)
	
	while !isnothing(iter)
		arraym,state = iter
		M', M = max(M'+a, a), max(M, M')
		iter = iterate(array, state)
	end
	return M
end
```

Определим iterate ля пользовательского типа данных

```julia
include("direct_robot.jl")

function Main. iterate(robot::DirectRobot)
	...
```


Принцип полиморфизма функций: более конкретные вызываются прежде более обощенных типов, по fallback абстрактности

```julia 

```

$$
A_{n}(x)=a_{0}+a_{1}x+a_{2}x^{2}+a_{2}x^{3}+\dots a_{n}x^{n}
$$
$$
B_{m}(x)=b_{0}+b_{1}x+b_{2}x^{2}+b_{2}x^{3}+\dots b_{n}x^{n}
$$

$$
C_{n+m}(x) = A_{n}(x)B-m
(x)$$
$$
\sum_{j=0}^{n}\sum_{j=0}^{m} a_{i}b_{j}x^{i+j}
$$
Если мы положим $i+j = k$, таких членов будет много, вручную мы бы приводили подобные члены

$$
C_{k}=\sum_{i+j=k}a_{i}b_{j}
$$
> [!note] Такая запись правильная! Это сумма элементов i j удв k

$$
c=\text{zeros(T, m+n+1)}
$$
```julia
for j in 1:m+1
	for j in 1:n+1
		c[i+j-1]+= a[i]*b[j]
	end
end
```
Сложность $\text{O(m * n)}$
пусть m =n
можно сделать ща $\text{O(n*log(n))}$

```julia
function Main. *(a::Polynom{T}, b::Polynom{T}) where T
	coeff = zeros(T, ord(a) + ord(b) + 1)
	for i in eachindex(a.coeff), j in eachindex(b.coeff)
		coeff[i+j-1]+= a.coeff[i]*b.coeff[j]
	end
	return Polynom{T}(coeff)
```

```julia
function valder(p::Polynom, x::T) where T
	Q, Q' = zero(T), zero(T)
	for i in reverese(eachindex(p.coeff))
		Q', Q = Q'*x+Q, Q*x + p.coeff[i]
	end
	return Q, Q'
end

julia> p = Polynom{Int}([3,2,1])
julia> valder(p,1)
out: (6,4)
```
 
 
 ## Автоматическое дифференцирование


Задачи машинного обучения сводятся к:
$f(w_{1},w_{2},w_{3},\dots)$ $\to$ надо минимизировать

$\frac{f(x+\Delta x)-f(x)}{\Delta x}\implies f(x), \Delta x\to0$
почему маленькая $\Delta x$ не всегда обеспечивает max точность? Дело в том, что входные данные имеют погрешность (округления и тд)
$\exists$ x в области неопределенности, то ошибка будет увеличиваться и неравильно аппроксимироваться касательные к прямой
с $\Delta$ погрешность сказывается сильнее
Если у нас длинна мантиссы - 16 дес разрядов, то оптимальным считается 1e-8
Встает проблема выбора приращения.

### Производная заданной аналитической функции

$f(x+\epsilon)=f(x)+f'(x)\epsilon + O(\epsilon^{2}),~ \epsilon \to0$

### Дуальные числа
они похожи на комлпексные числа
$a+b\epsilon$
$a,b \in\mathbb{R}$, $\epsilon^{2}=0$
В этом кольце имеются делители нуля, равные $a\epsilon ~\forall a\in\mathbb{R}$
a -  вещественная часть
b - дуальная часть

любую аналитическую функцию (представима рядами тейлора) можно распространить на дуальные числа
$f(a+b\epsilon)=f(a)+f'(a)b\epsilon$

Нужно взять значение дуального аргумента и подставить в формулу ряда Тейлора

### Примеры

1. $f(x)=3x^{2}+2x+1$
$f(x+\epsilon)=3(x+\epsilon)^{2} + 2(x+\epsilon)+1 = 3x^{2} + 6x\epsilon + \epsilon^{2} + 2x + 2\epsilon + 1 = (3x^{2} + 2x + 1)+(6x+2)\epsilon$
2. $f(x)=e^{\sin ^{2}(x)}$
$f'(x)=e^{\sin ^{2}(x)}2\sin(x)\cos(x)=e^{\sin ^{2}(x)}\sin (2x)$

$f(x+\epsilon)=?$
$\sin(x+\epsilon)=\sin(x)+\cos(x)\epsilon$
$\sin ^{2}(x+\epsilon) = (\sin(x)+ \cos(x)\epsilon)^{2}=\sin ^{2}(x)+\sin(2x)\epsilon$
по определению ... оч быстро пролистали, хз

## Вторая пара

$x^{y}=e^{y\ln x}$

```julia
function valder(f::Function, x::T) where T
	x = Dual(x,1)
	y = f(x)
	return realpart(y), dualpart(y)
end
```

## Метод Ньютона

$f(x)=0$ - представляется рядом Тейлора (аналитическая функция)

Мы хотим построить последовательность $x_{0},x_{1},x_{2}, \dots, x_{n}\to x'-\text{корень уравнения}$

заменяем значение на дифференциал, получаем точку приближения $\to$ для каждой точки пока не получим приближенное значение


пусть $x_{n}$ - очередное приближене искомого корня

тогда мы можем в окрестности $x_{n}$ разложить функцию в ряд Тейлора
$f(x_{n}+\Delta x)=f(x_{n})+f'(x_{n})\Delta x + \bar{\bar{o}}(\Delta x)$  $\Delta x\to_{0}$

$f(x_{n})-f'(x_{n}) \underbrace{ \Delta x }_{ x-x_{n} }=y$
$\Delta x=x-x_{n}$
при $y = 0$; $x=x_{n+1}$

$$x_{n+1}=x_{n}-\frac{f(x_{n})}{f'(x_{n})}$$

Допустим есть функция $y = x^{2}$, хотим научиться вычислять $x=\sqrt{ y }$
$f(y)=x^{2}-y=0$ решение этого уравнения и будет $\sqrt{ y }$
$x=x(y)$
$$x_{n+1}=x_{n}-\frac{f(x_{n})}{f'(x_{n})}=x_{n}-\frac{x_{n}^{2}-y}{2x_{n}}$$
повторять до
$$
\frac{x_{n}^{2}-y}{2x_{n}} = \delta \text{(оч мелкое число)}
$$

## Метод деления отрезка пополам

$f(x)=0$
Отрезок локализации - на этом отрезке существует корень, он единственный, на концах отрезка функция принимает противоположные знаки (пересекает x)

для непрерывной функции и известного отрезка локализации:
1. вычислим значение в середине отрезка локализации
2. если знаки все еще разные - повторить и отбросить правую часть
3. знаки равные - отбрасываем левую половину
Это метод бисекции


```julia
function bisec(f::Function, (a,b); abs_tool=1e-15)
	@assert f(a)*f(b) < 0
	@assert a < b

	while b-a > abs_tool
		mean = (a+b)/2
		if f(a)*f(b)(mean) > 0
			a = mean
		else
			b = mean
		end
	end
	return (a+b)/2
end

julia> bisec(x->cos(x)-x, (0, pi/2))
```
Достаточно непрерывности функции, представления в виде ряда не требуется

## Как программировать метод Ньютона

$\Delta=\frac{f(x_{n})}{f'(x_{n})}$


$f(x)=0$, $f:\mathbb{R}\to \mathbb{R}$
$x_{0}, x_{1},x_{2},\dots, x_{n},\dots\to x'$     x' - корень
$f(x_{n}+\Delta x)=f(x_{n})+f'(x_{n})\Delta x+o(\Delta x), \Delta x\to0$

$f(x_{n} + f'(x_{n})(x-x_{n})=0$
$f(x_{n})+f'(x_{n})(x_{n+1}-x_{n})=0$
$f(x_{n})+f'(x_{n})(x_{n+1}-x_{n}=0)$
$x_{n+1}=x_{n}-\frac{f(x_{n})}{f'(x_{n})}=x_{n}-\Delta(x_{n})$
```julia
function newton(delta::Function, x; tool=1e-8, num_{maxiter} = 20)
	k=0
	dx = delta(x)
	while (k < num_{maxtier)}&& (abs(dx) > tool)
		x -= dx
		dx = delta(x)
		k += 1
	end

	if k > num_maxtier
		@warn("число итераций превысило установленный порог, равные $(num_ma[iter])$")
	end
	return x
end

julia> newton(x-> (cos(x)))
		
```


пусть $f_{1}(x_{1},x_{2})=0$
        $f_{2}(x_{1},x_{2})$
$F: \mathbb{R}^{2}\to \mathbb{R}^{2}$

$F(\vec{x})=(f_{1}(x_{1},x_{2}), f_{2}(x_{1},x_{2}))$

$F(x_{0}+\Delta x)=F(x_{0})+F'(x_{0})\Delta x\to \bar{\bar{o}}(||\Delta x||)$
$F'(x)=\text{grad F}=(\text{frad }f_{1}(x), \text{grad}f_{2}(x))$
$F'(x)=\nabla$
$F'(x)=\nabla F(x)=$
$$
=\begin{bmatrix}
\frac{\partial f_{1}}{\partial x_{1}}  & \frac{\partial f_{1}}{\partial x_{2}} \\
\frac{\partial f_{2}}{\partial x_{1}}  & \frac{\partial f_{2}}{\partial x_{2}}
\end{bmatrix}
$$